{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "models = df[['Model-10','Model-6','Model-2','Model-Seq','Model-Dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(true, pred, labels_z):\n",
    "    non_zero_idx = np.nonzero(true)\n",
    "    true_nz = true[non_zero_idx]\n",
    "    pred_nz = pred[non_zero_idx]\n",
    "    labels_nz = list(range(1,51))\n",
    "    recall_nz = recall_score(true_nz, pred_nz, labels=labels_nz, average='weighted')\n",
    "    recall_z = recall_score(true, pred, labels=labels_z, average='weighted')\n",
    "    return (recall_z, recall_nz)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(true, pred, labels_z):\n",
    "    non_zero_idx = np.nonzero(true)\n",
    "    true_nz = true[non_zero_idx]\n",
    "    pred_nz = pred[non_zero_idx]\n",
    "    labels_nz = list(range(1,51))\n",
    "    recall_nz = precision_score(true_nz, pred_nz, labels=labels_nz, average='weighted')\n",
    "    recall_z = precision_score(true, pred, labels=labels_z, average='weighted')\n",
    "    return (recall_z, recall_nz)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f(true, pred, labels_z):\n",
    "    non_zero_idx = np.nonzero(true)\n",
    "    true_nz = true[non_zero_idx]\n",
    "    pred_nz = pred[non_zero_idx]\n",
    "    labels_nz = list(range(1,51))\n",
    "    recall_nz = f1_score(true_nz, pred_nz, labels=labels_nz, average='weighted')\n",
    "    recall_z = f1_score(true, pred, labels=labels_z, average='weighted')\n",
    "    return (recall_z, recall_nz)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Model-10\n",
      "Recall with zeros:  0.8612036855518526\n",
      "Precision with zeros:  0.8496316060401254\n",
      "F1 Score with zeros:  0.8496360275924866\n",
      "\n",
      "\n",
      "Recall without zeros:  0.6487804878048781\n",
      "Precision without zeros:  0.8466692890894251\n",
      "F1 Score without zeros:  0.721653550909396\n",
      "\n",
      "\n",
      "\n",
      "Model:  Model-6\n",
      "Recall with zeros:  0.8178788472848461\n",
      "Precision with zeros:  0.8486108325294456\n",
      "F1 Score with zeros:  0.828594563879002\n",
      "\n",
      "\n",
      "Recall without zeros:  0.676219512195122\n",
      "Precision without zeros:  0.8769931304527143\n",
      "F1 Score without zeros:  0.7508310216434684\n",
      "\n",
      "\n",
      "\n",
      "Model:  Model-2\n",
      "Recall with zeros:  0.845716526171339\n",
      "Precision with zeros:  0.8467672065163493\n",
      "F1 Score with zeros:  0.8409513297855009\n",
      "\n",
      "\n",
      "Recall without zeros:  0.6542682926829269\n",
      "Precision without zeros:  0.8584056167075903\n",
      "F1 Score without zeros:  0.729663933320814\n",
      "\n",
      "\n",
      "\n",
      "Model:  Model-Seq\n",
      "Recall with zeros:  0.7190746912370124\n",
      "Precision with zeros:  0.6766723942770873\n",
      "F1 Score with zeros:  0.6801990159249027\n",
      "\n",
      "\n",
      "Recall without zeros:  0.3170731707317073\n",
      "Precision without zeros:  0.5974276829481783\n",
      "F1 Score without zeros:  0.3724116080642094\n",
      "\n",
      "\n",
      "\n",
      "Model:  Model-Dist\n",
      "Recall with zeros:  0.8647324054107037\n",
      "Precision with zeros:  0.8631651819558779\n",
      "F1 Score with zeros:  0.8528548242948392\n",
      "\n",
      "\n",
      "Recall without zeros:  0.6451219512195122\n",
      "Precision without zeros:  0.8874151639488986\n",
      "F1 Score without zeros:  0.725194076758345\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_label = df[['Label']].values\n",
    "labels_z = list(range(51))\n",
    "for (columnName, columnData) in models.iteritems():\n",
    "    print('Model: ', columnName)\n",
    "    predictions = columnData.values.reshape((columnData.shape[0],1))\n",
    "    (recall_z, recall_nz) = get_recall(true_label, predictions, labels_z)\n",
    "    (precision_z, precision_nz) = get_precision(true_label, predictions, labels_z)\n",
    "    (f1_z, f1_nz) = get_f(true_label, predictions, labels_z)\n",
    "    print('Recall with zeros: ', recall_z)\n",
    "    print('Precision with zeros: ', precision_z)\n",
    "    print('F1 Score with zeros: ', f1_z)\n",
    "    print('\\n')\n",
    "    print('Recall without zeros: ', recall_nz)\n",
    "    print('Precision without zeros: ', precision_nz)\n",
    "    print('F1 Score without zeros: ', f1_nz)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
